{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import textacy\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.lang.en import English\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\").resolve()\n",
    "assert data_dir.exists()\n",
    "data_dir.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2d73f",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "Here we will explore App Reviews for just one app: Uber (Passenger/Cab, not the Driver). The additional data to reproduce this for other clients is left as an exercise for you.\n",
    "\n",
    "But to get an overview of all of them, we combine them into a larger single text string and explore them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_dir / \"Uber_us_app_store_reviews.json\"; assert file_path.exists()\n",
    "with file_path.open(\"r\") as f:\n",
    "    raw_data = pd.read_json(f)\n",
    "    reviews = \" \".join(raw_data[\"review\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time reviews = [rev.strip() for rev in reviews]\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time corpus = textacy.Corpus(\"en_core_web_sm\", data=reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.n_docs, corpus.n_sents, corpus.n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aab5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = corpus.word_counts(by=\"lemma_\", filter_stops= True, filter_nums=True, filter_punct=True)\n",
    "sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4857513d",
   "metadata": {},
   "source": [
    "Even after disabling the components, it will take extremely long durations and a lot of memory to process our relatively \"small data\". The solution? Batch your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11285e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class TextSummary:\n",
    "    def __init__(self, records: List[str]):\n",
    "        self.token_summary = self.make_summary(self.extract_tokens(records))\n",
    "        self.token_stats = self.get_corpora_stats(self.token_summary)\n",
    "\n",
    "    def extract_tokens(self, records: List[str]):\n",
    "        token_vocab = []\n",
    "        for doc in tokenizer.pipe(records):\n",
    "            token_vocab.append(Counter([str(x) for x in doc]))\n",
    "        return token_vocab\n",
    "\n",
    "    def make_summary(self, record_summaries: List[Counter]):\n",
    "        \"\"\"Get a Count Distribution for the entire Corpora\"\"\"\n",
    "        corpora_summary = record_summaries[0]\n",
    "        for record in tqdm(record_summaries[1:]):\n",
    "            corpora_summary += record\n",
    "\n",
    "        return corpora_summary\n",
    "\n",
    "    def get_corpora_stats(self, summary: List[Counter]):\n",
    "        self.vocab = list(summary.keys())\n",
    "        self.vocab_sz = len(self.vocab)\n",
    "        self.size = sum(summary[key] for key in summary.keys())\n",
    "        return {\"size\": self.size, \"vocab_sz\": self.vocab_sz, \"vocab\": self.vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b96160",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm = TextSummary(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.token_summary.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for doc in tqdm(nlp.pipe(reviews, batch_size=100, n_process=-1), total=len(reviews)):\n",
    "    for chunk in doc.noun_chunks:\n",
    "        print(chunk.text)\n",
    "# with multiproc, n_process=-1: 53s without 84s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4daa05",
   "metadata": {},
   "source": [
    "## Topic Modeling with Textacy via Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7507f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d44e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = ((term.lemma_ for term in textacy.extract.terms(doc, ngs=1, ents=True)) for doc in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d88166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.representations.vectorizers import Vectorizer\n",
    "vectorizer = Vectorizer(tf_type=\"linear\", idf_type=\"smooth\", norm=\"l2\",min_df=3, max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = vectorizer.fit_transform(tokenized_docs)\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.tm import TopicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75dee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TopicModel(\"nmf\", n_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919078d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix = model.transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, topics=range(20)):\n",
    "    print(\"topic\", topic_idx, \":\", \"   \".join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, top_docs in model.top_topic_docs(doc_topic_matrix, topics=[0,1], top_n=2):\n",
    "    print(topic_idx)\n",
    "    for j in top_docs:\n",
    "        print(j, corpus[j])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163def59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df71b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
