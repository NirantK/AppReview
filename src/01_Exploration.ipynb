{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy==3.0\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install textacy\n",
    "# !pip install scattertext\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import scattertext as st\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```TODO next:``` \n",
    "\n",
    "1. spaCy v3 Tokenize. Create a vocabulary of words. Do a Zipf's plot. \n",
    "2. Find common nouns, verbs using textacy/v3 of the same\n",
    "3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_reviews(data_path: Path) -> dict:\n",
    "    all_reviews = data_path.ls()\n",
    "    reviews = []\n",
    "    for review in all_reviews:\n",
    "        try:\n",
    "            data = json.load(review.open(\"r\"))\n",
    "            if data:\n",
    "                app_reviews = [item[\"review\"] for item in data]\n",
    "                reviews += app_reviews\n",
    "        except:\n",
    "            pass\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = read_all_reviews(data_path)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"\\n\".join(reviews))\n",
    "doc.vocab.to_disk(\"./vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [token.lemma_ for token in doc]\n",
    "json.dump(Counter(data), (data_path / \"frequency_count.json\").open(\"w\"), indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
